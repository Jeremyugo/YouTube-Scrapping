{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YouTube Statistics\n",
    "\n",
    "$by: Jeremiah\\space Chinyelugo$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining the api key and channel id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_key = 'INPUT YUR API KEY HERE'\n",
    "# channel_id = 'INPUT THE CHANNEL ID'\n",
    "\n",
    "# #find chanel id using (https://commentpicker.com/youtube-channel-id.php)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Class for getting channel stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTube_Stats:\n",
    "    \n",
    "    ''' Initializing the api_key & Id of the channel we want to work with '''\n",
    "    def __init__(self, api_key, channel_id):\n",
    "        self.api_key = api_key\n",
    "        self.channel_id = channel_id\n",
    "        self.video_id = None\n",
    "        self.channel_statistics = None\n",
    "        \n",
    "    \n",
    "    ''' Method to get the channel statistics '''\n",
    "    def get_channel_statistics(self):\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/channels?part=statistics&id={self.channel_id}&key={self.api_key}\"\n",
    "        r = requests.get(url)\n",
    "        data = r.json()\n",
    "        try:\n",
    "            data = data['items'][0]['statistics']\n",
    "        except:\n",
    "            data = None\n",
    "        \n",
    "        self.channel_statistics = data\n",
    "        return data\n",
    "    \n",
    "    ''' Retrieves specified properties for each video_id '''\n",
    "    def get_channel_video_data(self):\n",
    "        channel_videos = self._get_channel_videos(limit=50)\n",
    "        \n",
    "        parts = ['snippet','statistics','contentDetails']\n",
    "        for video_id in tqdm(channel_videos):\n",
    "            for part in parts:\n",
    "                data = self._get_single_video_data(video_id, part)\n",
    "                channel_videos[video_id].update(data)\n",
    "        \n",
    "        self.video_data = channel_videos\n",
    "        return channel_videos\n",
    "        \n",
    "        \n",
    "        \n",
    "    ''' Retrieves a video's data. video_id of the video and \n",
    "    part(specifies what property or properties you want to retrieve e.g \"statistics\") \n",
    "    are required '''    \n",
    "    def _get_single_video_data(self, video_id, part):\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/videos?part={part}&id={video_id}&key={self.api_key}\"\n",
    "        r = requests.get(url)\n",
    "        data = r.json()\n",
    "        try:\n",
    "            data = data['items'][0][part]\n",
    "        except:\n",
    "            print('error')\n",
    "            data = dict()\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    ''' Limits and retrieves the video Id retrieved from the next method'''\n",
    "    def _get_channel_videos(self, limit=None):\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/search?key={self.api_key}&channelId={self.channel_id}&part=snippet,id&order=date\"\n",
    "        if limit is not None and isinstance(limit, int):\n",
    "            url = url + \"&maxResults=\" + str(limit)\n",
    "            \n",
    "        vid, npt = self._get_channel_videos_per_page(url)\n",
    "        idx = 0\n",
    "        while (npt is not None and idx < 10):\n",
    "            nexturl = url + '&pageToken=' + npt\n",
    "            next_vid, npt = self._get_channel_videos_per_page(nexturl)\n",
    "            vid.update(next_vid)\n",
    "            idx = idx + 1\n",
    "        \n",
    "        return vid\n",
    "        \n",
    "    ''' Retrieves video Id's for each page and the NextPageToken for other \n",
    "    video Id\"s '''    \n",
    "    def _get_channel_videos_per_page(self, url):\n",
    "        r = requests.get(url)\n",
    "        data = r.json()\n",
    "        channel_videos = dict()\n",
    "        if 'items' not in data:\n",
    "            return channel_videos, None\n",
    "        \n",
    "        item_data = data['items']\n",
    "        nextPageToken = data.get('nextPageToken', None)\n",
    "        for item in item_data:\n",
    "            try:\n",
    "                kind = item['id']['kind']\n",
    "                if kind == 'youtube#video':\n",
    "                    video_id = item['id']['videoId']\n",
    "                    channel_videos[video_id] = dict()\n",
    "            except KeyError:\n",
    "                print('Error')\n",
    "                \n",
    "        return channel_videos, nextPageToken\n",
    "    \n",
    "    \n",
    "    def dump(self):\n",
    "        if self.channel_statistics is None or self.video_data is None:\n",
    "            print('No Data Available')\n",
    "            return\n",
    "        \n",
    "        fused_data = {self.channel_id: {'channel_statistics': self.channel_statistics, 'video_data': self.video_data}}\n",
    "        channel_title = self.video_data.popitem()[1].get('channelTitle', self.channel_id)\n",
    "        channel_title = channel_title.replace(' ','_').lower()\n",
    "        filename = channel_title + '.json'\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(fused_data, f, indent = 4)\n",
    "        \n",
    "        print('File dumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 172/172 [01:30<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File dumped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "yt = YouTube_Stats(api_key, channel_id)\n",
    "yt.get_channel_statistics()\n",
    "yt.get_channel_video_data()\n",
    "yt.dump()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the json file\n",
    "json file has already been saved in the current directory, replace the file name below with the json filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of file\n",
    "filename = 'kurzgesagt_–_in_a_nutshell'\n",
    "\n",
    "with open(filename+'.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "channel_id = [x for x in data.keys()][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channel_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_stats = data[channel_id]['channel_statistics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewCount</th>\n",
       "      <th>subscriberCount</th>\n",
       "      <th>hiddenSubscriberCount</th>\n",
       "      <th>videoCount</th>\n",
       "      <th>channelName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2225065056</td>\n",
       "      <td>20100000</td>\n",
       "      <td>False</td>\n",
       "      <td>172</td>\n",
       "      <td>kurzgesagt_–_in_a_nutshell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    viewCount subscriberCount  hiddenSubscriberCount videoCount  \\\n",
       "0  2225065056        20100000                  False        172   \n",
       "\n",
       "                  channelName  \n",
       "0  kurzgesagt_–_in_a_nutshell  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channel_stats = pd.DataFrame([channel_stats.values()], columns=channel_stats.keys())\n",
    "df_channel_stats['channelName'] = filename\n",
    "df_channel_stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data = data[channel_id]['video_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_data = pd.DataFrame([])\n",
    "\n",
    "video_ids = [x for x in video_data.keys()]\n",
    "properties = ['publishedAt', 'title', 'description', 'viewCount', 'likeCount', 'commentCount', 'duration']\n",
    "\n",
    "for prop in properties:\n",
    "    list_ = []\n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            data = video_data[video_id][prop]\n",
    "        except KeyError:\n",
    "            data = 0\n",
    "        list_.append(data)\n",
    "    df_video_data[prop] = list_\n",
    "df_video_data['channelName'] = filename"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_data['publishedAt'] = pd.to_datetime(df_video_data['publishedAt']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stripping PT away to make manipulation easier\n",
    "df_video_data['duration'] = df_video_data['duration'].str.strip('PT')\n",
    "\n",
    "\n",
    "\n",
    "# extracting minutes and seconds\n",
    "minutes = [x[0] for x in df_video_data['duration'].str.split('M')]\n",
    "seconds = [x[1] for x in df_video_data['duration'].str.split('M')]\n",
    "\n",
    "df_video_data['seconds'] = seconds\n",
    "df_video_data['minutes'] = minutes\n",
    "\n",
    "# converting minutes to seconds\n",
    "df_video_data['seconds'] = df_video_data['seconds'].str.strip('S')\n",
    "df_video_data['seconds'] = np.where(df_video_data['seconds'] == '', 0, df_video_data['seconds'])\n",
    "\n",
    "# adding converted minutes to seconds\n",
    "df_video_data['duration_seconds'] = df_video_data['seconds'].astype(np.int) + (df_video_data['minutes'].astype(np.int) * 60)\n",
    "\n",
    "# cleaning video description\n",
    "def clean_description(x):\n",
    "    matches = re.findall(r\"\\s\\s[A-Za-z0-9.&'‘’“”,\\s\\?\\–\\-:…%!()]+\\s\\s\", x)\n",
    "    return sorted(matches, key=len, reverse=True)[0].strip('\\n')\n",
    "\n",
    "df_video_data['cleaned_description'] = df_video_data['description'].apply(clean_description)\n",
    "\n",
    "# extra cleaning\n",
    "\n",
    "def extra_clean(x):\n",
    "    matches = re.findall(r\"[A-Za-z0-9.&'‘’“”,\\s\\?\\–\\-:…%!()]+\\s\\s\", x)\n",
    "    return matches[0].strip('\\n')\n",
    "\n",
    "# noticed some instances that needed further cleaning\n",
    "lists = [102,154,103,124,127,141,143,133,140,150,126,128,136,142,139,131,151,93,138,134,148,152,147,122,137,110,86,87,89,90,91,96,101,135,106,111,117,125,121,118,120,116,112,113,114,144,153,78,79,82,83]\n",
    "\n",
    "df_video_data.loc[lists, 'cleaned_description'] = df_video_data.loc[lists,'description'].apply(extra_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_data.drop(['seconds', 'minutes'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>duration</th>\n",
       "      <th>channelName</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>cleaned_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>The Most Complex Language in the World</td>\n",
       "      <td>Go ‘beyond the nutshell’ at https://brilliant....</td>\n",
       "      <td>2872959</td>\n",
       "      <td>174991</td>\n",
       "      <td>9396</td>\n",
       "      <td>11M55S</td>\n",
       "      <td>kurzgesagt_–_in_a_nutshell</td>\n",
       "      <td>715</td>\n",
       "      <td>You are cells. Your muscles, organs, skin and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>Black Hole Star – The Star That Shouldn't Exist</td>\n",
       "      <td>Try Rocket Money for free &amp; unlock more featur...</td>\n",
       "      <td>6392760</td>\n",
       "      <td>311920</td>\n",
       "      <td>14719</td>\n",
       "      <td>12M23S</td>\n",
       "      <td>kurzgesagt_–_in_a_nutshell</td>\n",
       "      <td>743</td>\n",
       "      <td>Black hole stars may have been the largest sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-11</td>\n",
       "      <td>How To Terraform Mars - WITH LASERS</td>\n",
       "      <td>Go ‘beyond the nutshell’ at https://brilliant....</td>\n",
       "      <td>4825687</td>\n",
       "      <td>224507</td>\n",
       "      <td>13410</td>\n",
       "      <td>11M28S</td>\n",
       "      <td>kurzgesagt_–_in_a_nutshell</td>\n",
       "      <td>688</td>\n",
       "      <td>Mars is a disappointing hellhole lacking pract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>The Horror of the Slaver Ant</td>\n",
       "      <td>Offset your carbon footprint on Wren: ​https:/...</td>\n",
       "      <td>5406221</td>\n",
       "      <td>263591</td>\n",
       "      <td>9677</td>\n",
       "      <td>10M44S</td>\n",
       "      <td>kurzgesagt_–_in_a_nutshell</td>\n",
       "      <td>644</td>\n",
       "      <td>Everything changed when the slaver nation atta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>The Most Extreme Explosion in the Universe</td>\n",
       "      <td>Go ‘beyond the nutshell’ at https://brilliant....</td>\n",
       "      <td>5396261</td>\n",
       "      <td>222701</td>\n",
       "      <td>7804</td>\n",
       "      <td>11M19S</td>\n",
       "      <td>kurzgesagt_–_in_a_nutshell</td>\n",
       "      <td>679</td>\n",
       "      <td>Supernovae are the most powerful explosions in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>The History and Future of Everything -- Time</td>\n",
       "      <td>How much time do you have left?\\n\\nTime makes ...</td>\n",
       "      <td>7396276</td>\n",
       "      <td>185074</td>\n",
       "      <td>13704</td>\n",
       "      <td>7M10S</td>\n",
       "      <td>kurzgesagt_–_in_a_nutshell</td>\n",
       "      <td>430</td>\n",
       "      <td>Short videos, explaining things. For example E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2013-11-28</td>\n",
       "      <td>How The Stock Exchange Works (For Dummies)</td>\n",
       "      <td>Why are there stocks at all?\\n\\nEveryday in th...</td>\n",
       "      <td>8190633</td>\n",
       "      <td>129034</td>\n",
       "      <td>8621</td>\n",
       "      <td>3M34S</td>\n",
       "      <td>kurzgesagt_–_in_a_nutshell</td>\n",
       "      <td>214</td>\n",
       "      <td>Everyday in the news we hear about the stock e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2013-10-11</td>\n",
       "      <td>The Gulf Stream Explained</td>\n",
       "      <td>Learn about the role of the sea in global warm...</td>\n",
       "      <td>5811034</td>\n",
       "      <td>63711</td>\n",
       "      <td>1968</td>\n",
       "      <td>5M4S</td>\n",
       "      <td>kurzgesagt_–_in_a_nutshell</td>\n",
       "      <td>304</td>\n",
       "      <td>The global conveyer belt is part of the large-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2013-09-03</td>\n",
       "      <td>Fracking explained: opportunity or danger</td>\n",
       "      <td>Fracking explained in five minutes.\\n\\nFrackin...</td>\n",
       "      <td>7158396</td>\n",
       "      <td>100165</td>\n",
       "      <td>8086</td>\n",
       "      <td>5M3S</td>\n",
       "      <td>kurzgesagt_–_in_a_nutshell</td>\n",
       "      <td>303</td>\n",
       "      <td>Fracking is a controversial topic. On the one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2013-08-22</td>\n",
       "      <td>The Solar System -- our home in space</td>\n",
       "      <td>An Infographic trip through the wonders of the...</td>\n",
       "      <td>5954725</td>\n",
       "      <td>81991</td>\n",
       "      <td>6122</td>\n",
       "      <td>7M21S</td>\n",
       "      <td>kurzgesagt_–_in_a_nutshell</td>\n",
       "      <td>441</td>\n",
       "      <td>The solar system - well known from countless d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    publishedAt                                            title  \\\n",
       "0    2023-02-14           The Most Complex Language in the World   \n",
       "1    2022-12-15  Black Hole Star – The Star That Shouldn't Exist   \n",
       "2    2022-12-11              How To Terraform Mars - WITH LASERS   \n",
       "3    2022-12-06                     The Horror of the Slaver Ant   \n",
       "4    2022-11-23       The Most Extreme Explosion in the Universe   \n",
       "..          ...                                              ...   \n",
       "166  2013-12-19     The History and Future of Everything -- Time   \n",
       "167  2013-11-28       How The Stock Exchange Works (For Dummies)   \n",
       "168  2013-10-11                        The Gulf Stream Explained   \n",
       "169  2013-09-03        Fracking explained: opportunity or danger   \n",
       "170  2013-08-22            The Solar System -- our home in space   \n",
       "\n",
       "                                           description viewCount likeCount  \\\n",
       "0    Go ‘beyond the nutshell’ at https://brilliant....   2872959    174991   \n",
       "1    Try Rocket Money for free & unlock more featur...   6392760    311920   \n",
       "2    Go ‘beyond the nutshell’ at https://brilliant....   4825687    224507   \n",
       "3    Offset your carbon footprint on Wren: ​https:/...   5406221    263591   \n",
       "4    Go ‘beyond the nutshell’ at https://brilliant....   5396261    222701   \n",
       "..                                                 ...       ...       ...   \n",
       "166  How much time do you have left?\\n\\nTime makes ...   7396276    185074   \n",
       "167  Why are there stocks at all?\\n\\nEveryday in th...   8190633    129034   \n",
       "168  Learn about the role of the sea in global warm...   5811034     63711   \n",
       "169  Fracking explained in five minutes.\\n\\nFrackin...   7158396    100165   \n",
       "170  An Infographic trip through the wonders of the...   5954725     81991   \n",
       "\n",
       "    commentCount duration                 channelName  duration_seconds  \\\n",
       "0           9396   11M55S  kurzgesagt_–_in_a_nutshell               715   \n",
       "1          14719   12M23S  kurzgesagt_–_in_a_nutshell               743   \n",
       "2          13410   11M28S  kurzgesagt_–_in_a_nutshell               688   \n",
       "3           9677   10M44S  kurzgesagt_–_in_a_nutshell               644   \n",
       "4           7804   11M19S  kurzgesagt_–_in_a_nutshell               679   \n",
       "..           ...      ...                         ...               ...   \n",
       "166        13704    7M10S  kurzgesagt_–_in_a_nutshell               430   \n",
       "167         8621    3M34S  kurzgesagt_–_in_a_nutshell               214   \n",
       "168         1968     5M4S  kurzgesagt_–_in_a_nutshell               304   \n",
       "169         8086     5M3S  kurzgesagt_–_in_a_nutshell               303   \n",
       "170         6122    7M21S  kurzgesagt_–_in_a_nutshell               441   \n",
       "\n",
       "                                   cleaned_description  \n",
       "0    You are cells. Your muscles, organs, skin and ...  \n",
       "1    Black hole stars may have been the largest sta...  \n",
       "2    Mars is a disappointing hellhole lacking pract...  \n",
       "3    Everything changed when the slaver nation atta...  \n",
       "4    Supernovae are the most powerful explosions in...  \n",
       "..                                                 ...  \n",
       "166  Short videos, explaining things. For example E...  \n",
       "167  Everyday in the news we hear about the stock e...  \n",
       "168  The global conveyer belt is part of the large-...  \n",
       "169  Fracking is a controversial topic. On the one ...  \n",
       "170  The solar system - well known from countless d...  \n",
       "\n",
       "[171 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving dataframe in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_data.to_csv(filename+'.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ~ The End ~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
